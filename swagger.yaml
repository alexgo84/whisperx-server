openapi: 3.0.3
info:
  title: Transcription Service
  description: |-
    This is a Python server Application that transcribes media files.
    The service recieves requests to transcribe file through the endpoint '/transcribe'.
    Once a request was received, the server will start the transcription work and post the result to the indicated place when finished.
    This service will only process one file at a time and will additional requests while processing is ongoing.

    Some useful links:
    - [Whisperx](https://github.com/m-bain/whisperX) used for generating the transcriptions.
    - [FastAPI](https://fastapi.tiangolo.com/) used for implementing the server.
  version: 1.0.0
paths:
  /transcribe:
    post:
      summary: Request the transcription of media
      description: This endpoint is used to request the transcription of a media file.
      operationId: transcribe
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TranscriptionRequest'
        required: true
      responses:
        '202':
          description: Request Accepted - the file processing has begun.
        '400':
          description: Bad Request - the request body did not contain the expected object.
        '529':
          description: Service Overloaded - a video is currently being processed. Try again later.
        '404':
          description: File not found - the requested file could not be located in storage.

components:
  schemas:
    TranscriptionRequest:
      type: object
      required: [ pathToFile ]
      properties:
        pathToFile:
          type: string
          description: The path to the file for the transcription.
          format: filename
          example: 'videos/2022-02-28/abcd-edfh.mk4'
        outputPath:
          type: string
          description: The path to which the server should place the transcription. If not provided the output will be put in the same directory as the source file.
          format: directory
          example: 'videos/2022-02-28'
        modelSize:
          type: string
          description: The type of model that should be used for the transcription. Larger models produce more accurate transcriptions, but require more processing time. If this value is not provided the large model will be used.
          enum:
            - small
            - medium
            - large
            - large-v2